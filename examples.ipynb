{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e64923d-b5fe-4255-bab9-560fb126b132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#install editable version of this repository\n",
    "# !python -m pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d659b989-3e26-47fe-b0e9-eabc091e7b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "from importlib import reload\n",
    "\n",
    "#imports \n",
    "import torch\n",
    "from torch.cuda import memory_allocated, empty_cache\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Import local functions ==================================\n",
    "import activation_extractor\n",
    "# from activation_extractor import *\n",
    "# reload(activation_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27def865-badc-4403-b974-204c111692b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'activation_extractor' from '/orfeo/cephfs/scratch/area/evillegas/glm/activation-extractor/src/activation_extractor/__init__.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from activation_extractor.extractors import intermediateExtractorBase \n",
    "# reload(intermediateExtractorBase)\n",
    "# from activation_extractor.inferencers import inferencerBase\n",
    "# reload(inferencerBase)\n",
    "from activation_extractor.model_functions import load_models, tokenize_funs, inference_funs, default_hooked_layers\n",
    "reload(load_models)\n",
    "reload(tokenize_funs)\n",
    "reload(inference_funs)\n",
    "reload(default_hooked_layers)\n",
    "\n",
    "# from activation_extractor.model_functions import embedding_to_numpy\n",
    "# reload(embedding_to_numpy)\n",
    "# from activation_extractor.model_functions.embedding_to_numpy import *\n",
    "reload(activation_extractor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80040e65-180b-4ec5-be6f-d834e7d18213",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Proteins/DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e97acbb-0c05-4b56-8452-59a6527f4518",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dataset(\"ILSVRC/imagenet-1k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f84723a-f0c2-4cb4-9040-b1dba9814759",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/esm2_t48_15B_UR50D\"\n",
    "inferencer = activation_extractor.Inferencer(model_name, device=None, half=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a51aa-3aa3-4df3-980b-1c422d893174",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1, l2, l3 = [], [], []\n",
    "for i in range(0,32):\n",
    "    l1.append(inferencer.model.blocks[i].mlp.l1.weight.norm().detach().cpu().to(torch.float32).numpy())\n",
    "    l2.append(inferencer.model.blocks[i].mlp.l2.weight.norm().detach().cpu().to(torch.float32).numpy())\n",
    "    l3.append(inferencer.model.blocks[i].mlp.l3.weight.norm().detach().cpu().to(torch.float32).numpy())\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(l1)\n",
    "plt.plot(l2)\n",
    "plt.plot(l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40c55d7-585a-4bb9-9feb-e135563f2182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequences = [\"AAAAA\", \"PPPPPP\"]\n",
    "sequences = [\"AAAA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c927f6ad-26ce-42ba-983b-c8c162657c5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#intermediate activation extractor\n",
    "layers_to_hook = activation_extractor.get_layers_to_hook(inferencer.model,inferencer.model_type)\n",
    "extractor = activation_extractor.IntermediateExtractor(inferencer.model, layers_to_hook)\n",
    "extractor.register_hooks()\n",
    "\n",
    "#inference\n",
    "processed = inferencer.process(sequences) #tokenize\n",
    "outputs = inferencer.inference(processed)\n",
    "\n",
    "#extractor outputs\n",
    "#extractor.save_outputs('results/embeddings/test')\n",
    "extractor.clear_all_hooks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ca1dd8-5d55-4323-a2e2-61233ad04ac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extractor.get_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849e1f05-eb17-47f0-8499-dd57a288da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b25a5-e2f7-4b95-abb5-3d863e66abf5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b86a6bf-00eb-4c8c-9b0c-72be443f5cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34fe08e-4270-4279-9973-eaeb190f605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"timm/vgg16.tv_in1k\"\n",
    "inferencer = activation_extractor.Inferencer(model_name, device='cuda', half=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42197cb2-8548-417c-8b92-b9a6ce5c5027",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#intermediate activation extractor\n",
    "layers_to_hook = activation_extractor.get_layers_to_hook(inferencer.model,inferencer.model_type)\n",
    "extractor = activation_extractor.IntermediateExtractor(inferencer.model, layers_to_hook)\n",
    "extractor.register_hooks()\n",
    "\n",
    "#inference\n",
    "processed = inferencer.process(sequences) #tokenize\n",
    "outputs = inferencer.inference(processed)\n",
    "\n",
    "#extractor outputs\n",
    "#extractor.save_outputs('results/embeddings/test')\n",
    "extractor.clear_all_hooks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4548feef-b365-49de-b4fd-6f0700bb4acd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extractor.get_outputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7373797a-2057-47c9-8322-596fd58a2db5",
   "metadata": {},
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e1fae1-c9dc-4204-9883-96e68e1d628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/HazyResearch/flash-attention.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f6c2a1b-2139-4f1f-9e66-2d802d3f556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import requests\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fa025ff-aa14-4ece-af8c-75af9273c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"ChristophSchuhmann/MS_COCO_2017_URL_TEXT\")\n",
    "text = ds['train']['TEXT'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fd9fed7-70f8-48ac-8fbd-6445ddb2db5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53afae3e9c85493b8a66495ec6856ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"togethercomputer/StripedHyena-Nous-7B\"\n",
    "inferencer = activation_extractor.Inferencer(model_name, device=\"cuda\", half=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69b3fa40-4623-47fc-a9d0-9cc9aef9d8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing inference params...\n"
     ]
    }
   ],
   "source": [
    "#intermediate activation extractor\n",
    "layers_to_hook = activation_extractor.get_layers_to_hook(inferencer.model,inferencer.model_type, modality=\"sequence\")\n",
    "extractor = activation_extractor.IntermediateExtractor(inferencer.model, layers_to_hook)\n",
    "extractor.register_hooks()\n",
    "\n",
    "#inference\n",
    "processed = inferencer.process(text) #tokenize\n",
    "outputs = inferencer.inference(processed)\n",
    "\n",
    "#extractor outputs\n",
    "#extractor.save_outputs('results/embeddings/test')\n",
    "extractor.clear_all_hooks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "314c35ec-768b-434e-8f62-8980db5c241c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "backbone.embedding_layer not in dictionary\n"
     ]
    }
   ],
   "source": [
    "seq_length=processed['attention_mask'].reshape(-1).shape[0]-1\n",
    "extractor.save_outputs('test', output_id=1, \n",
    "                       emb_formats=[\"custom\"], custom_position=seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb57c03-d901-40ff-b877-b0bf0a0baff7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87474f58-46ea-435b-ae91-8ad136f7ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import requests\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486348cc-01b9-41ce-87ec-0d6482081458",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"ChristophSchuhmann/MS_COCO_2017_URL_TEXT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddecaac-2b52-4488-9790-17b503cee31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 501\n",
    "\n",
    "# Open the image file\n",
    "#online\n",
    "url = ds['train']['URL'][idx]\n",
    "# image = Image.open(requests.get(url, stream=True).raw)\n",
    "# image = np.array(image)\n",
    "\n",
    "#locally\n",
    "local_path =  \"../data/train2017/\"\n",
    "image_path = ds['train']['URL'][idx].split(\"/\")[-1]\n",
    "# image_path = dataset['URL'][idx].split(\"/\")[-1]\n",
    "image_path = os.path.join(local_path,image_path)\n",
    "img = Image.open(image_path)\n",
    "img_array = np.array(img)\n",
    "\n",
    "if len(img_array.shape)==2:\n",
    "    img_array =  np.stack((img_array,) * 3, axis=-1)\n",
    "    \n",
    "plt.imshow(img_array)\n",
    "\n",
    "#text\n",
    "text = ds['train']['TEXT'][idx]\n",
    "print(text)\n",
    "\n",
    "#inputs\n",
    "input_data = {\"text\":text,\n",
    "             \"image\":img_array\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33dc55e-9506-4e38-b108-6ba003cd11e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"openai/clip-vit-base-patch32\"\n",
    "inferencer = activation_extractor.Inferencer(model_name, device='cpu', half=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a2c63-bad0-495f-8951-00556b0582b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intermediate activation extractor\n",
    "layers_to_hook = activation_extractor.get_layers_to_hook(inferencer.model,inferencer.model_type, modality=\"image-text\")\n",
    "extractor = activation_extractor.IntermediateExtractor(inferencer.model, layers_to_hook)\n",
    "extractor.register_hooks()\n",
    "\n",
    "#inference\n",
    "processed = inferencer.process(input_data) #tokenize\n",
    "outputs = inferencer.inference(processed)\n",
    "\n",
    "#extractor outputs\n",
    "#extractor.save_outputs('results/embeddings/test')\n",
    "extractor.clear_all_hooks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d5a68f-986f-48da-bddd-cbf2b6e6ba39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extractor.get_outputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1483d3-2e8c-40f5-8937-20330a2f4166",
   "metadata": {},
   "source": [
    "# Inference Over a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c562185-0578-478f-b515-23723c1eba42",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6a8238-ab54-472e-a9fd-23d894663e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from activation_extractor.scripts.inference import main_inference, load_the_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b99e0f4-600c-4cbe-8c97-b21e873ab0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"Rostlab/ProstT5\"\n",
    "output_folder=\"test\"\n",
    "emb_format=\"mean\"\n",
    "save_method=\"numpy\"\n",
    "max_batches=1\n",
    "\n",
    "data_args = {\n",
    "        \"data_type\":\"protein\",\n",
    "        \"batch_size\":8,\n",
    "        \"data_source\":\"huggingface\",\n",
    "        \"dataset_name\":\"proteinea/remote_homology\",\n",
    "        \"dataset_partition\":\"train\",\n",
    "        \"target_col\":\"primary\",\n",
    "        # \"data_source\":\"local\",\n",
    "        # \"target_col\":\"protein_seq\",\n",
    "        # \"input_path\":\"/orfeo/LTS/LADE/LT_storage/bio_data/NCBI/NCBI_GP_from_geneid_Plt1000_Glt6000.csv\",\n",
    "        \"max_length\":1000,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2d0d56-373d-4ea0-99ca-6efd4cbb29d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = load_the_data(**data_args)\n",
    "batch = next(iter(data_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e647a010-964a-4c7b-84d7-bc0c9ef15a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_inference(model_name, output_folder, emb_format, save_method, max_batches, data_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f3776-1571-4afe-81c1-42b9fc4817c4",
   "metadata": {},
   "source": [
    "## For Images/text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51a15578-aa94-4cf9-b06a-dcb4c35081ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from activation_extractor.scripts.inference import main_inference, load_the_data\n",
    "\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34b72d38-311c-49ce-8fa2-0aff81fc26d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"ChristophSchuhmann/MS_COCO_2017_URL_TEXT\")\n",
    "ds = pd.DataFrame(ds['train'])\n",
    "ds.drop_duplicates(subset=['URL'])\n",
    "ds = Dataset.from_pandas(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b5b943d-29da-478e-8e6c-62b9c7ca2db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"togethercomputer/StripedHyena-Nous-7B\"\n",
    "# model_name=\"google/vit-base-patch16-224-in21k\"\n",
    "output_folder=\"test\"\n",
    "emb_format=\"mean\"\n",
    "save_method=\"numpy\"\n",
    "max_batches=1\n",
    "\n",
    "data_args = {\n",
    "        \"data_type\":\"mscoco\",\n",
    "        # \"modality\":\"image-text\",\n",
    "        \"modality\":\"text\",\n",
    "        # \"modality\": \"image\",\n",
    "        \"batch_size\":1,\n",
    "        \"data_source\":\"huggingface\",\n",
    "        \"dataset_name\":\"ChristophSchuhmann/MS_COCO_2017_URL_TEXT\",\n",
    "        \"dataset_partition\":\"train\",\n",
    "        # \"data_source\":\"local\",\n",
    "        # \"input_path\":\"test.csv\",\n",
    "        \"image_source\":\"local\",\n",
    "        \"image_dir\":\"../data/train2017\",\n",
    "    }\n",
    "\n",
    "save_args = {\n",
    "        \"save_method\":\"numpy\",\n",
    "        \"emb_formats\":['LT','FT','mean'],\n",
    "        \"sequence_axis\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92c6b8af-7441-44f9-892a-0ff1b24f4208",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = load_the_data(**data_args)\n",
    "input_data = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40bb2068-215a-4df3-a4e7-5dec5ed52088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/scratch/area/evillegas/glm/dgxtorch/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9351e5b3a39f410d9bc080a2ab6516db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folder is: test/togethercomputer/StripedHyena-Nous-7B\n",
      "Initializing inference params...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "✔️ togethercomputer/StripedHyena-Nous-7B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/togethercomputer/StripedHyena-Nous-7B\n",
      "0\n",
      "False\n",
      "True\n",
      "numpy\n",
      "['LT', 'FT', 'mean']\n",
      "1\n",
      "None\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/orfeo/cephfs/scratch/area/evillegas/glm/activation-extractor/src/activation_extractor/scripts/inference.py:249\u001b[0m, in \u001b[0;36mmain_inference\u001b[0;34m(model_name, output_folder, save_args, max_batches, data_args)\u001b[0m\n\u001b[1;32m    245\u001b[0m     sys\u001b[38;5;241m.\u001b[39mexit()\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m### Saving Part ###\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m## intermediate activations\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m \u001b[43mextractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moutput_folder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m                       \u001b[49m\u001b[43moutput_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_i\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mmove_to_cpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msave_args\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#also creates folder\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdna\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprotein\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;66;03m#tokens\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     tokens\u001b[38;5;241m=\u001b[39membedding_to_numpy(processed[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/orfeo/cephfs/scratch/area/evillegas/glm/activation-extractor/src/activation_extractor/extractors/intermediateExtractor.py:114\u001b[0m, in \u001b[0;36mIntermediateExtractor.save_outputs\u001b[0;34m(self, output_folder, output_id, reset, move_to_cpu, save_method, emb_formats, sequence_axis, custom_position)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name,outputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_outputs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;66;03m#reformat outputs\u001b[39;00m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m emb_format \u001b[38;5;129;01min\u001b[39;00m emb_formats:\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;66;03m#reformat outputs\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memb_reformatting\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m                             \u001b[49m\u001b[43memb_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memb_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m                             \u001b[49m\u001b[43msequence_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msequence_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcustom_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m                            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;66;03m#different saving functions\u001b[39;00m\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;28;01mmatch\u001b[39;00m save_method:\n",
      "File \u001b[0;32m/orfeo/cephfs/scratch/area/evillegas/glm/activation-extractor/src/activation_extractor/extractors/intermediateExtractor.py:56\u001b[0m, in \u001b[0;36mIntermediateExtractor.emb_reformatting\u001b[0;34m(self, outputs, emb_format, sequence_axis, custom_position)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mmatch\u001b[39;00m emb_format:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 56\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msequence_axis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLT\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFT\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     59\u001b[0m         token_position \u001b[38;5;241m=\u001b[39m token_position_dict[emb_format]\n",
      "File \u001b[0;32m/orfeo/cephfs/scratch/area/evillegas/glm/dgxtorch/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3501\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 3504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3505\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/orfeo/cephfs/scratch/area/evillegas/glm/dgxtorch/lib/python3.10/site-packages/numpy/core/_methods.py:106\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    102\u001b[0m arr \u001b[38;5;241m=\u001b[39m asanyarray(a)\n\u001b[1;32m    104\u001b[0m is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m rcount \u001b[38;5;241m=\u001b[39m \u001b[43m_count_reduce_items\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rcount \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m umr_any(rcount \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    108\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean of empty slice.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/orfeo/cephfs/scratch/area/evillegas/glm/dgxtorch/lib/python3.10/site-packages/numpy/core/_methods.py:77\u001b[0m, in \u001b[0;36m_count_reduce_items\u001b[0;34m(arr, axis, keepdims, where)\u001b[0m\n\u001b[1;32m     75\u001b[0m     items \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m axis:\n\u001b[0;32m---> 77\u001b[0m         items \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mshape[\u001b[43mmu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_axis_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     78\u001b[0m     items \u001b[38;5;241m=\u001b[39m nt\u001b[38;5;241m.\u001b[39mintp(items)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# TODO: Optimize case when `where` is broadcast along a non-reduction\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# axis and full sum is more excessive than needed.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# guarded to protect circular imports\u001b[39;00m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "main_inference(model_name, output_folder, save_args, max_batches, data_args)\n",
    "        print(output_folder)\n",
    "        print(output_id)\n",
    "        print(reset)\n",
    "        print(move_to_cpu)\n",
    "        print(save_method)\n",
    "        print(emb_formats)\n",
    "        print(sequence_axis)\n",
    "        print(custom_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a980c8-38bd-484a-8153-33f084555c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f442b9-514a-48df-8bcf-d77b03cec4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dcb720-5501-437e-8653-2fc31a3bbffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf19605-8978-4d64-b79f-a31a2dd9cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_pil(batch):\n",
    "    \"\"\"\n",
    "    Convert PIL images to numpy arrays.\n",
    "    \"\"\"\n",
    "    batch = [np.array(img) for img in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f42446-953d-4e33-8f31-ea8184c7c108",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [ np.array(dataset[\"train\"][\"img\"][i]) for i in range(10) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7169b68-643b-46c8-829d-1428e8a35e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c0cb2d-6f19-4937-9ee0-a54d76dfe23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR100\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65508f08-305e-4d22-80d6-9a141ec40331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))  # Normalize the images\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR100(\n",
    "    root='./data',  # Directory to store the dataset\n",
    "    train=True,  # Download the training dataset\n",
    "    download=True,  # Download if not already downloaded\n",
    "    transform=transform  # Apply transformations\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,  # Number of samples per batch\n",
    "    shuffle=True,  # Shuffle the dataset\n",
    "    num_workers=2,  # Number of subprocesses to use for data loadingt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18357c87-50c0-4f2e-90fb-80238e770017",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(train_dataset, batch_size=2, \n",
    "                             shuffle=False, collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823a8310-3ef3-4731-b82c-9b9b49645ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "dataset = load_dataset(\"uoft-cs/cifar100\")\n",
    "data_loader = DataLoader(dataset[\"train\"], batch_size=2, \n",
    "                             shuffle=False, collate_fn=collate_pil)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
