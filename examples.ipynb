{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e64923d-b5fe-4255-bab9-560fb126b132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#install editable version of this repository\n",
    "# !python -m pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d659b989-3e26-47fe-b0e9-eabc091e7b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/scratch/area/evillegas/glm/dgxtorch/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys\n",
    "from importlib import reload\n",
    "\n",
    "#imports \n",
    "import torch\n",
    "from torch.cuda import memory_allocated, empty_cache\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Import local functions ==================================\n",
    "import activation_extractor\n",
    "# from activation_extractor import *\n",
    "# reload(activation_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27def865-badc-4403-b974-204c111692b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from activation_extractor.extractors import intermediateExtractorBase \n",
    "# reload(intermediateExtractorBase)\n",
    "# from activation_extractor.inferencers import inferencerBase\n",
    "# reload(inferencerBase)\n",
    "# from activation_extractor.model_functions import load_models, tokenize_funs, inference_funs, default_hooked_layers\n",
    "# reload(load_models)\n",
    "# reload(tokenize_funs)\n",
    "# reload(inference_funs)\n",
    "# reload(default_hooked_layers)\n",
    "\n",
    "# from activation_extractor.model_functions import embedding_to_numpy\n",
    "# reload(embedding_to_numpy)\n",
    "# from activation_extractor.model_functions.embedding_to_numpy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80040e65-180b-4ec5-be6f-d834e7d18213",
   "metadata": {},
   "source": [
    "# Proteins/DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f84723a-f0c2-4cb4-9040-b1dba9814759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e4624b960048fba57ef109845b289a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 22 files:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"EvolutionaryScale/esm3-sm-open-v1\"\n",
    "inferencer = activation_extractor.Inferencer(model_name, device='cuda', half=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f40c55d7-585a-4bb9-9feb-e135563f2182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequences = [\"AAAAA\", \"PPPPPP\"]\n",
    "sequences = [\"MEME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c927f6ad-26ce-42ba-983b-c8c162657c5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "#intermediate activation extractor\n",
    "layers_to_hook = activation_extractor.get_layers_to_hook(inferencer.model,inferencer.model_type)\n",
    "extractor = activation_extractor.IntermediateExtractor(inferencer.model, layers_to_hook)\n",
    "extractor.register_hooks()\n",
    "\n",
    "#inference\n",
    "processed = inferencer.process(sequences) #tokenize\n",
    "outputs = inferencer.inference(processed)\n",
    "\n",
    "#extractor outputs\n",
    "#extractor.save_outputs('results/embeddings/test')\n",
    "extractor.clear_all_hooks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47ca1dd8-5d55-4323-a2e2-61233ad04ac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoder.sequence_embed': tensor([[[ 0.0776, -0.0176,  0.0410,  ..., -0.0295, -0.0197, -0.0006],\n",
       "          [-0.0952,  0.1201,  0.0962,  ..., -0.0042,  0.2295,  0.1191],\n",
       "          [ 0.0106, -0.0052,  0.0649,  ...,  0.2139, -0.0654, -0.1748],\n",
       "          [-0.0952,  0.1201,  0.0962,  ..., -0.0042,  0.2295,  0.1191],\n",
       "          [ 0.0106, -0.0052,  0.0649,  ...,  0.2139, -0.0654, -0.1748],\n",
       "          [ 0.0598,  0.0299,  0.0173,  ..., -0.0312, -0.0217, -0.0162]]],\n",
       "        device='cuda:0', grad_fn=<EmbeddingBackward0>),\n",
       " 'transformer.blocks.0.attn': tensor([[[ 1.1538,  1.6749,  0.4084,  ..., -0.6493,  0.9303,  1.2165],\n",
       "          [ 0.8525,  1.9190,  0.9099,  ..., -0.5079,  0.9395,  1.6627],\n",
       "          [ 0.9522,  1.7643,  0.9005,  ..., -0.3768,  0.6052,  1.1339],\n",
       "          [ 1.0312,  1.7524,  0.8786,  ..., -0.4910,  1.0552,  1.4141],\n",
       "          [ 1.2086,  1.5762,  0.8577,  ..., -0.3488,  0.6748,  0.8711],\n",
       "          [ 1.2252,  1.4804,  0.5620,  ..., -0.6365,  0.9238,  0.9053]]],\n",
       "        device='cuda:0', grad_fn=<UnsafeViewBackward0>),\n",
       " 'transformer.blocks.0.geom_attn': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " 'transformer.blocks.0': tensor([[[ 3.6440,  9.5012, -0.0771,  ...,  0.8088, -0.5258,  0.2104],\n",
       "          [ 2.5412,  6.3865, -0.1345,  ..., -0.1225, -0.7775,  1.1018],\n",
       "          [ 2.6733,  6.0907,  0.0691,  ...,  0.0904, -1.3919,  0.5219],\n",
       "          [ 2.6089,  6.5517, -0.1085,  ..., -0.2568, -0.6271,  0.9403],\n",
       "          [ 2.9648,  6.3725,  0.0333,  ..., -0.1559, -1.2499,  0.4008],\n",
       "          [ 4.2183,  9.6958,  0.2335,  ...,  0.2541, -0.7031,  0.0566]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.1': tensor([[[ 2.0642,  5.5155,  0.1735,  ...,  3.6633, -1.5349, -2.5807],\n",
       "          [ 1.5174,  4.0763,  0.0241,  ...,  0.9725, -2.1372, -1.3208],\n",
       "          [ 1.5909,  3.6352,  0.2572,  ...,  1.1790, -2.6985, -2.1467],\n",
       "          [ 1.6848,  4.1456,  0.1008,  ...,  1.0283, -1.9828, -1.4582],\n",
       "          [ 2.0438,  3.6946,  0.2829,  ...,  1.1898, -2.5503, -2.3312],\n",
       "          [ 2.4203,  5.6556,  0.0724,  ...,  3.5621, -2.1503, -2.8658]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.2': tensor([[[ 0.8844,  5.8873,  0.8090,  ...,  2.6574, -2.7424, -2.6785],\n",
       "          [ 0.8156,  4.3821,  0.4428,  ...,  0.2550, -2.2738, -0.3187],\n",
       "          [ 0.9029,  4.1054,  0.6278,  ...,  0.4822, -2.8839, -1.1216],\n",
       "          [ 0.7949,  4.3768,  0.3848,  ...,  0.5046, -2.1920, -0.3705],\n",
       "          [ 1.0280,  4.1006,  0.5851,  ...,  0.8220, -2.8372, -1.3257],\n",
       "          [ 0.6500,  5.6220,  0.5443,  ...,  3.3302, -3.2010, -3.0848]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.3': tensor([[[ 0.8510,  6.7153,  1.4653,  ...,  3.7908, -3.0452, -2.4080],\n",
       "          [ 1.1131,  4.6451,  1.2978,  ...,  1.4525, -2.2016, -0.2476],\n",
       "          [ 0.8503,  4.2253,  1.2325,  ...,  1.5577, -2.9381, -1.2504],\n",
       "          [ 1.2281,  4.4179,  1.2032,  ...,  1.5701, -1.7463, -0.2144],\n",
       "          [ 1.1858,  4.0675,  1.0498,  ...,  1.6536, -2.8267, -1.4409],\n",
       "          [ 0.3377,  6.7137,  1.0295,  ...,  4.0634, -2.9568, -2.6193]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.4': tensor([[[ 0.9606,  5.8516,  0.3531,  ...,  2.9660, -1.6920, -2.7270],\n",
       "          [ 0.7681,  4.0443, -0.0503,  ...,  0.6342,  0.3082, -0.5867],\n",
       "          [ 0.6798,  3.4146, -0.3956,  ...,  1.2455, -0.7306, -1.3183],\n",
       "          [ 1.2066,  3.2304, -0.1304,  ...,  0.7444,  0.4860, -0.3210],\n",
       "          [ 1.1827,  2.9985, -0.1406,  ...,  1.1405, -0.9791, -1.4239],\n",
       "          [ 0.7177,  5.5369,  0.0718,  ...,  3.3648, -2.0034, -2.8243]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.5': tensor([[[ 1.1659,  5.3205,  0.6534,  ...,  2.2251, -1.0553, -3.6405],\n",
       "          [ 0.9965,  3.6133, -0.3906,  ..., -0.4571,  0.8339, -1.2981],\n",
       "          [ 1.0186,  3.0758, -0.7164,  ...,  0.3646, -0.7447, -1.8642],\n",
       "          [ 1.4799,  3.2447, -0.1587,  ..., -0.2933,  1.1846, -0.7008],\n",
       "          [ 1.4025,  3.1867, -0.2122,  ..., -0.0611, -0.5429, -1.8017],\n",
       "          [ 1.1811,  5.3685,  0.5455,  ...,  2.3003, -0.7819, -3.5766]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.6': tensor([[[ 0.7686,  5.9258, -0.0176,  ...,  2.2044, -2.2719, -2.3558],\n",
       "          [ 0.3899,  3.5279, -0.8547,  ..., -0.2108, -0.0557, -0.5871],\n",
       "          [ 0.4213,  3.3728, -0.9490,  ...,  0.7260, -1.6692, -1.1363],\n",
       "          [ 1.0314,  3.2400, -0.4300,  ...,  0.2314,  0.7263,  0.1096],\n",
       "          [ 0.8262,  3.5689, -0.6310,  ...,  0.4638, -1.2657, -1.1210],\n",
       "          [ 0.9151,  5.8589, -0.2707,  ...,  2.4009, -1.9167, -2.5179]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.7': tensor([[[ 1.1930e+00,  5.7945e+00, -1.7878e-01,  ...,  2.0267e+00,\n",
       "           -2.5589e+00, -3.2567e+00],\n",
       "          [ 3.3046e-01,  3.6094e+00, -7.0158e-01,  ..., -3.5892e-01,\n",
       "           -5.6912e-01, -1.0023e+00],\n",
       "          [ 5.5027e-01,  3.4677e+00, -8.4193e-01,  ...,  7.0410e-01,\n",
       "           -1.9313e+00, -1.5751e+00],\n",
       "          [ 9.4152e-01,  3.2478e+00, -1.4147e-01,  ...,  1.4308e-02,\n",
       "            4.7800e-01, -2.7790e-01],\n",
       "          [ 7.5865e-01,  3.5570e+00, -2.2448e-01,  ...,  2.1484e-01,\n",
       "           -1.5435e+00, -2.0981e+00],\n",
       "          [ 1.2572e+00,  5.5150e+00, -2.0920e-03,  ...,  2.0544e+00,\n",
       "           -2.0130e+00, -3.6851e+00]]], device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.8': tensor([[[ 1.1328,  5.4996, -0.5316,  ...,  2.2641, -2.6009, -2.6003],\n",
       "          [ 0.1551,  3.2388, -1.3822,  ..., -0.0519, -0.5774, -0.3835],\n",
       "          [ 0.0653,  3.1614, -1.6385,  ...,  1.2285, -1.8022, -0.8144],\n",
       "          [ 0.3767,  2.8787, -0.4743,  ...,  0.2524,  1.1365,  0.1370],\n",
       "          [ 0.4966,  3.1779, -1.0744,  ...,  0.6561, -1.6480, -1.2717],\n",
       "          [ 1.3914,  5.2486, -0.4145,  ...,  2.0034, -1.9591, -2.9043]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.9': tensor([[[ 0.7558,  6.4457, -1.2346,  ...,  2.0194, -2.1638, -1.9457],\n",
       "          [-0.1493,  4.2404, -1.6270,  ..., -0.1119, -0.0776,  0.5574],\n",
       "          [ 0.1252,  4.0436, -1.9123,  ...,  1.2191, -1.8714,  0.1375],\n",
       "          [ 0.2822,  3.5049, -0.1900,  ...,  0.2328,  1.7640,  1.5250],\n",
       "          [ 0.1614,  3.6473, -1.4277,  ...,  0.6106, -1.4848,  0.0936],\n",
       "          [ 0.5914,  5.6293, -0.8955,  ...,  1.6467, -1.3027, -1.7559]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.10': tensor([[[ 0.5155,  5.1784, -1.2932,  ...,  1.8676, -2.3883, -1.5704],\n",
       "          [-0.0698,  2.8501, -1.6457,  ..., -0.2576, -0.1045,  0.8331],\n",
       "          [ 0.1337,  2.2993, -1.7567,  ...,  1.2286, -2.3709,  0.5353],\n",
       "          [ 0.2764,  1.5204, -0.6626,  ...,  0.0408,  2.1438,  1.8652],\n",
       "          [ 0.1752,  1.7944, -1.8195,  ...,  0.0997, -2.0269,  0.3993],\n",
       "          [ 0.3540,  4.0470, -1.2284,  ...,  1.3209, -1.4579, -1.3705]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.11': tensor([[[ 0.5659,  5.2893, -1.0902,  ...,  1.7436, -2.5456, -1.4021],\n",
       "          [ 0.3463,  2.5739, -1.2384,  ..., -0.5068,  0.2858,  1.0058],\n",
       "          [-0.1019,  1.8756, -0.8093,  ...,  0.8521, -2.0937,  0.7820],\n",
       "          [ 0.4841,  1.3338, -0.2334,  ..., -0.2324,  2.3442,  2.1515],\n",
       "          [-0.1771,  1.5192, -1.2023,  ..., -0.2444, -1.9903,  0.4277],\n",
       "          [ 0.5215,  4.2122, -1.0404,  ...,  0.9620, -1.8033, -1.2234]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.12': tensor([[[ 0.1281,  5.7521, -1.0461,  ...,  1.3086, -1.9017, -1.3516],\n",
       "          [-0.0215,  2.8631, -1.3905,  ..., -1.0613,  0.9181,  0.8506],\n",
       "          [-0.9173,  2.4662, -0.8168,  ...,  0.3653, -1.3118,  0.6311],\n",
       "          [ 0.0093,  1.4534, -0.4404,  ..., -0.8671,  3.2699,  2.1473],\n",
       "          [-0.8462,  2.0227, -1.1593,  ..., -0.7662, -1.0058,  0.4780],\n",
       "          [ 0.2539,  4.5545, -1.0130,  ...,  0.2295, -0.8247, -1.1626]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.13': tensor([[[ 0.9844,  6.2175, -1.3906,  ...,  0.5708, -1.7109, -1.3829],\n",
       "          [ 0.7807,  3.2660, -1.8260,  ..., -1.9734,  0.9975,  0.6122],\n",
       "          [-0.4696,  2.9208, -0.8340,  ..., -0.3941, -1.0357,  0.5862],\n",
       "          [ 0.6564,  2.1584, -0.4539,  ..., -1.4466,  3.7273,  2.2510],\n",
       "          [-0.4573,  2.6844, -0.8326,  ..., -1.2694, -0.5969,  0.5667],\n",
       "          [ 0.9620,  5.1647, -1.1694,  ..., -0.2949, -0.4111, -1.2361]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.14': tensor([[[ 9.7945e-01,  5.7932e+00, -1.8600e+00,  ...,  8.9564e-02,\n",
       "           -1.4163e+00, -1.3592e+00],\n",
       "          [ 9.3079e-01,  2.8795e+00, -2.3586e+00,  ..., -2.4202e+00,\n",
       "            1.7033e+00,  5.6326e-01],\n",
       "          [-5.5155e-01,  2.4183e+00, -1.0509e+00,  ..., -9.3274e-01,\n",
       "           -1.0106e+00,  7.2767e-01],\n",
       "          [ 9.0972e-01,  1.9322e+00, -1.0905e+00,  ..., -1.8833e+00,\n",
       "            4.2987e+00,  2.0852e+00],\n",
       "          [-1.7119e-01,  2.3094e+00, -1.2407e+00,  ..., -2.1142e+00,\n",
       "           -7.3689e-01,  5.0746e-01],\n",
       "          [ 1.2372e+00,  5.0289e+00, -1.9549e+00,  ..., -1.1979e+00,\n",
       "           -9.9234e-04, -1.3668e+00]]], device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.15': tensor([[[ 1.5307,  5.5382, -2.1574,  ...,  0.8051, -1.9616, -1.8278],\n",
       "          [ 1.5655,  2.4766, -2.6969,  ..., -1.5486,  0.7808, -0.1601],\n",
       "          [-0.2762,  2.0019, -1.0994,  ..., -0.8612, -2.1470,  0.2607],\n",
       "          [ 1.0483,  2.0411, -1.0792,  ..., -1.4698,  3.3063,  1.6547],\n",
       "          [ 0.0091,  2.1901, -1.0244,  ..., -2.2657, -1.4413, -0.0198],\n",
       "          [ 1.5865,  4.8286, -2.0973,  ..., -0.6232, -0.5577, -1.6738]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.16': tensor([[[ 1.9775,  5.2344, -2.7687,  ...,  0.2178, -1.6266, -1.9850],\n",
       "          [ 2.0602,  2.7447, -3.1481,  ..., -3.3536,  1.6661, -0.9830],\n",
       "          [ 0.1251,  1.6478, -1.4600,  ..., -1.3408, -1.6863,  0.0250],\n",
       "          [ 1.6231,  2.0135, -1.6378,  ..., -3.2492,  3.8070,  0.8738],\n",
       "          [ 0.2661,  1.7542, -1.4512,  ..., -2.9571, -1.2460, -0.2762],\n",
       "          [ 2.2800,  4.3787, -2.5255,  ..., -1.5706, -0.1094, -2.0162]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.17': tensor([[[ 2.1484,  4.8608, -2.4950,  ..., -0.3777, -2.6101, -2.0865],\n",
       "          [ 2.5505,  2.4724, -2.1803,  ..., -4.3245,  0.2000, -1.1850],\n",
       "          [ 0.6845,  1.2634, -0.7763,  ..., -2.2184, -2.8332, -0.4886],\n",
       "          [ 2.3035,  1.9142, -0.6225,  ..., -4.4652,  2.2654,  0.4647],\n",
       "          [ 1.1226,  1.1914, -0.9129,  ..., -3.9773, -2.0769, -0.7391],\n",
       "          [ 2.6424,  3.9934, -2.1615,  ..., -2.4566, -0.9545, -2.0225]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.18': tensor([[[ 1.8235,  4.5240, -1.3758,  ...,  0.5556, -1.7230, -1.9165],\n",
       "          [ 2.5623,  1.9962, -0.9095,  ..., -3.4316,  1.0301, -0.8548],\n",
       "          [ 0.6885,  0.7772,  0.2884,  ..., -1.2928, -1.7903, -0.3626],\n",
       "          [ 2.1570,  1.5876,  0.5553,  ..., -3.5591,  3.0241,  0.9563],\n",
       "          [ 1.3670,  0.7624,  0.1081,  ..., -2.7855, -1.1766, -0.5086],\n",
       "          [ 2.5147,  3.7604, -0.9987,  ..., -1.3882, -0.0893, -1.7551]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.19': tensor([[[ 1.0831,  4.1623, -1.5138,  ...,  0.6435, -1.1195, -1.2863],\n",
       "          [ 1.6914,  2.1958, -0.7756,  ..., -3.4010,  1.9262, -0.8272],\n",
       "          [ 0.0635,  0.6337,  0.0520,  ..., -1.1766, -0.9783, -0.0578],\n",
       "          [ 1.2721,  2.1552,  0.6303,  ..., -3.5658,  3.8882,  1.0379],\n",
       "          [ 0.8104,  0.7594, -0.0764,  ..., -2.4678, -0.2918, -0.2780],\n",
       "          [ 1.8235,  3.8024, -0.9294,  ..., -1.1147,  0.5698, -1.4022]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.20': tensor([[[ 1.7913,  4.1842, -1.3867,  ...,  0.9305, -0.8530, -0.7830],\n",
       "          [ 2.3184,  2.2657, -0.5954,  ..., -2.9367,  2.1069, -0.4098],\n",
       "          [ 1.3073,  0.6676,  0.5833,  ..., -1.1525, -0.2337,  0.6799],\n",
       "          [ 1.8498,  2.1261,  0.9557,  ..., -3.3915,  4.1835,  1.2200],\n",
       "          [ 1.8843,  0.6382,  0.3738,  ..., -2.6117,  0.6831,  0.6632],\n",
       "          [ 2.4158,  3.6451, -0.6802,  ..., -0.8654,  1.0147, -0.9897]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.21': tensor([[[ 1.5727,  4.4601, -1.6240,  ...,  0.8113,  0.1745, -0.1277],\n",
       "          [ 1.9327,  2.3162, -0.5462,  ..., -3.1499,  3.1991,  0.3820],\n",
       "          [ 1.2327,  0.8860,  0.2380,  ..., -2.0468,  0.8804,  1.7458],\n",
       "          [ 1.4793,  2.0372,  1.0508,  ..., -3.6705,  5.1020,  1.9547],\n",
       "          [ 1.7467,  0.7944, -0.0802,  ..., -3.5003,  1.9521,  1.4974],\n",
       "          [ 2.2201,  3.6228, -0.9147,  ..., -1.1267,  2.0255, -0.4034]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.22': tensor([[[ 1.8417,  4.4879, -1.0360,  ...,  0.8155, -0.0413,  0.3175],\n",
       "          [ 1.9949,  1.9430,  0.3974,  ..., -2.9752,  3.5643,  0.2539],\n",
       "          [ 1.0924,  0.5491,  0.9280,  ..., -2.5960,  0.6159,  1.7994],\n",
       "          [ 1.5872,  1.5214,  2.0072,  ..., -3.6828,  5.1210,  2.0166],\n",
       "          [ 1.4761,  0.1459,  0.8190,  ..., -4.1067,  1.9825,  1.5681],\n",
       "          [ 2.4188,  2.9867,  0.2187,  ..., -1.4147,  1.7401, -0.1595]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.23': tensor([[[ 0.9749,  4.8643, -0.9517,  ...,  1.7004, -1.0375, -0.3204],\n",
       "          [ 1.8419,  3.0024,  0.6860,  ..., -3.1248,  2.3550,  0.1779],\n",
       "          [-0.1051,  2.0128,  1.3856,  ..., -2.5785,  0.6538,  1.5362],\n",
       "          [ 1.6028,  3.7730,  2.4517,  ..., -4.8406,  3.9558,  2.3759],\n",
       "          [ 0.4549,  1.1713,  1.4064,  ..., -3.9551,  2.2191,  1.3744],\n",
       "          [ 1.4271,  3.4996,  0.4043,  ..., -0.5414,  0.8827, -0.6929]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.24': tensor([[[ 2.2041,  5.3351, -1.3667,  ...,  0.3609, -1.0257, -1.0467],\n",
       "          [ 1.5645,  3.2663,  1.3875,  ..., -4.2584,  2.4331,  0.8519],\n",
       "          [ 1.0672,  2.2686,  0.9946,  ..., -3.2928,  0.2558,  1.7681],\n",
       "          [ 0.2526,  4.0382,  3.6590,  ..., -6.5910,  4.0720,  2.7880],\n",
       "          [ 1.3017,  1.7521,  0.8077,  ..., -4.7670,  1.5032,  1.3176],\n",
       "          [ 2.1813,  4.3041, -0.0535,  ..., -2.1596,  0.4999, -1.3603]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.25': tensor([[[ 1.4322,  4.1292, -1.2932,  ...,  2.3246,  0.2411, -1.9121],\n",
       "          [ 1.3223,  2.7576,  1.0369,  ..., -1.9994,  3.8303,  0.1154],\n",
       "          [ 0.4550,  0.6598,  0.9748,  ..., -0.0237,  1.1596,  1.6520],\n",
       "          [ 0.3779,  3.0791,  2.5942,  ..., -3.6879,  5.5406,  1.9623],\n",
       "          [ 0.6915,  0.1208,  0.7950,  ..., -1.5917,  2.9730,  0.8942],\n",
       "          [ 1.6729,  3.6653, -0.1946,  ...,  0.2422,  2.3195, -1.8696]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.26': tensor([[[ 1.8762,  3.5615, -1.6501,  ...,  0.8823,  1.5865, -3.4872],\n",
       "          [ 1.0142,  1.7529,  1.1241,  ..., -3.4642,  4.2582, -0.8294],\n",
       "          [ 0.4126,  0.7305,  1.3269,  ..., -1.4100,  1.9538,  1.1648],\n",
       "          [ 0.4777,  1.4398,  2.5162,  ..., -4.7613,  5.5996,  0.6807],\n",
       "          [ 1.0147, -0.2786,  1.4729,  ..., -3.1230,  3.5292,  0.2485],\n",
       "          [ 2.2289,  2.5956, -0.0281,  ..., -1.5376,  3.6794, -3.5778]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.27': tensor([[[ 1.1375,  3.3605, -2.1427,  ..., -0.0505,  3.7893, -3.5634],\n",
       "          [-1.5184,  1.7682,  1.0070,  ..., -4.5592,  4.6536, -0.8956],\n",
       "          [-1.6216, -0.4677,  1.9705,  ..., -2.9181,  3.1101,  1.5477],\n",
       "          [-1.3221,  1.1134,  2.0589,  ..., -6.2290,  6.1069,  0.5342],\n",
       "          [ 0.6975, -0.6360,  1.7936,  ..., -5.1188,  4.5010, -0.1308],\n",
       "          [ 0.9826,  2.5816,  0.6028,  ..., -3.8187,  4.8353, -2.5954]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.28': tensor([[[ 0.2254,  2.3457, -3.1136,  ..., -0.7170,  2.9397, -3.4902],\n",
       "          [-1.4872,  1.5226,  0.1953,  ..., -5.0902,  4.9419,  0.8904],\n",
       "          [-1.5320,  1.3707,  2.9213,  ..., -3.6689,  2.2552,  1.6967],\n",
       "          [-1.0148,  2.7459,  1.0809,  ..., -5.4340,  7.0522,  2.7541],\n",
       "          [-0.2991, -0.2052,  0.9537,  ..., -6.2968,  3.9847, -0.0387],\n",
       "          [ 0.2428,  2.6653, -1.0544,  ..., -3.2308,  5.5210, -2.2295]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.29': tensor([[[ -0.0913,   1.4802,  -2.2749,  ...,  -0.6669,   2.5278,  -3.2234],\n",
       "          [ -1.5924,   2.2377,   0.4571,  ...,  -9.4730,   5.6905,   1.5081],\n",
       "          [ -0.7509,   3.9174,   3.7422,  ...,  -9.9588,   2.9833,   4.5973],\n",
       "          [ -1.3414,   1.6499,   1.1768,  ...,  -8.7545,   7.0688,   2.6468],\n",
       "          [  0.2075,   0.5670,   0.8912,  ..., -11.2184,   4.5696,   2.1698],\n",
       "          [  0.4654,   1.3993,  -0.3541,  ...,  -2.2143,   5.1404,  -3.4942]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.30': tensor([[[ -1.1386,   0.9480,  -4.2095,  ...,  -2.6922,   3.9635,  -3.3751],\n",
       "          [ -6.2239,  -0.6571,  -4.4241,  ..., -10.8669,   5.6869,   0.7952],\n",
       "          [ -2.9890,   1.5282,   1.3473,  ..., -10.2706,   4.9573,   3.2498],\n",
       "          [ -5.5138,  -1.2313,  -3.2737,  ..., -10.7626,   7.1919,   1.0710],\n",
       "          [ -2.5413,  -1.1582,  -2.0045,  ..., -10.6251,   5.5991,   0.9203],\n",
       "          [ -0.9872,  -0.0755,  -1.7823,  ...,  -4.1775,   5.8004,  -4.5170]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.31': tensor([[[-1.2636,  0.6180, -6.0886,  ..., -1.3677,  1.3109, -1.4769],\n",
       "          [-5.5802, -2.5813, -4.7878,  ..., -7.5561,  6.1098,  1.7851],\n",
       "          [-4.6758,  0.3964,  0.5192,  ..., -7.8919,  3.2001,  2.1540],\n",
       "          [-4.8456, -2.2096, -4.4617,  ..., -7.6677,  8.0187,  1.8112],\n",
       "          [-4.0345, -0.3884, -2.2414,  ..., -8.5234,  4.0743, -0.8507],\n",
       "          [-0.8962,  0.0334, -4.7378,  ..., -3.1973,  4.7239, -3.3531]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.32': tensor([[[  1.8622,  -3.0756,  -4.4048,  ...,  -4.5257,   4.2942,  -4.3391],\n",
       "          [ -5.7013,  -6.1233,  -3.6594,  ..., -10.2582,  11.2079,  -2.1570],\n",
       "          [ -4.5434,  -3.7658,   1.1203,  ..., -10.0242,   7.7064,  -2.6725],\n",
       "          [ -6.0433,  -6.6705,  -3.6108,  ..., -10.4016,  13.7070,  -2.4430],\n",
       "          [ -3.6134,  -4.6367,  -2.1102,  ..., -10.7241,   8.1344,  -6.5900],\n",
       "          [  1.0561,  -3.2784,  -3.9991,  ...,  -6.9848,   8.7905,  -7.7255]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.33': tensor([[[ 0.4663,  1.0589, -7.6317,  ..., -2.4906,  4.8068, -2.6961],\n",
       "          [-7.2782, -4.4882, -6.8999,  ..., -9.2453, 12.0219, -4.4124],\n",
       "          [-4.3452, -1.8926, -0.9994,  ..., -6.4572,  9.3598, -3.6799],\n",
       "          [-6.0047, -6.9109, -6.9890,  ..., -8.0222, 16.0702, -4.8427],\n",
       "          [-2.3194, -1.5913, -3.5643,  ..., -7.6490, 10.0155, -7.2240],\n",
       "          [ 1.2075, -1.6920, -8.0461,  ..., -4.9620,  8.1496, -7.1227]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.34': tensor([[[ -2.6047,  -3.1436,  -4.8221,  ...,  -3.6966,   4.8119,  -0.1541],\n",
       "          [-12.5061,  -6.0570,  -2.7327,  ...,  -7.9860,  12.5769,  -1.1734],\n",
       "          [ -9.9389,  -1.3870,   2.4156,  ...,  -4.8545,   8.6091,  -0.0520],\n",
       "          [-10.4612,  -6.3565,  -4.4976,  ...,  -7.9507,  16.3557,  -1.4990],\n",
       "          [ -6.2710,  -2.3079,  -0.3989,  ...,  -8.9942,   7.9451,  -3.4037],\n",
       "          [ -0.3601,  -2.6292,  -5.2018,  ...,  -5.2445,   7.9552,  -5.0517]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.35': tensor([[[ -0.4212,  -1.9917,  -5.9700,  ...,  -5.4272,   3.7430,   0.4616],\n",
       "          [-12.9108,  -2.9842,  -4.1979,  ..., -10.2390,   9.2639,  -3.4787],\n",
       "          [-10.8631,   4.4294,   0.0909,  ...,  -5.9658,   6.1488,  -2.8822],\n",
       "          [-11.7672,  -2.0695,  -8.1816,  ...,  -9.6896,  14.8084,  -3.5152],\n",
       "          [ -8.1876,   2.1248,  -1.4133,  ...,  -9.9015,   8.7240,  -7.4577],\n",
       "          [  1.6720,  -0.1478,  -5.9090,  ...,  -7.3833,   6.9857,  -4.8652]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.36': tensor([[[  1.2405,   3.8748,  -5.6060,  ...,  -8.1757,   4.8383,   1.7303],\n",
       "          [ -9.8547,  -0.8951,  -1.9041,  ..., -10.5212,  12.9962,  -0.8151],\n",
       "          [ -4.6530,   9.9096,   1.0609,  ...,  -5.2755,   7.2677,  -1.5727],\n",
       "          [ -6.1486,   0.6967, -11.0089,  ...,  -4.3854,  19.3069,  -1.9457],\n",
       "          [ -3.6876,   5.9315,  -1.5030,  ...,  -6.2200,   6.4353,  -6.8204],\n",
       "          [  3.7062,   3.4594,  -6.9412,  ...,  -1.9179,   8.6871,  -1.9096]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.37': tensor([[[  8.2337,  -0.5841,  -1.5495,  ...,  -6.3559,   6.9734,  -3.1859],\n",
       "          [ -4.7060,  -5.6968,   4.1417,  ...,  -9.6186,  14.4586,  -5.6242],\n",
       "          [ -2.4783,   3.8453,   7.3911,  ...,  -3.4702,  10.8097,  -5.3304],\n",
       "          [ -3.7164,  -6.8988,  -8.3186,  ...,  -2.4390,  24.5630,  -3.5329],\n",
       "          [  1.7234,  -1.6654,   2.9357,  ...,  -4.6856,   7.9788, -10.9392],\n",
       "          [  7.6458,  -2.0832,  -0.2284,  ...,   1.6939,  10.8274,  -0.7504]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.38': tensor([[[  8.1735,  -4.8310,  -4.7322,  ...,   1.5492,  11.2129,  -2.9058],\n",
       "          [ -6.8585, -13.5302,  -7.6245,  ..., -19.4908,  -1.9444,  -7.9652],\n",
       "          [ -3.9089,   8.3467,   4.1212,  ..., -16.2357,  10.3125,  -1.7503],\n",
       "          [ -1.8482, -16.1030, -13.5672,  ...,  -6.5997,  11.8189, -10.6274],\n",
       "          [  1.6564,   0.4321,  -0.7417,  ..., -12.1254,  12.1863,  -7.0371],\n",
       "          [  2.5608,  -3.1592,   2.7573,  ...,  18.0148,   6.8071,  -4.5612]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.39': tensor([[[ 5.2139e+00, -1.6380e+01, -3.4129e+00,  ...,  9.3223e+00,\n",
       "            1.8166e+01,  4.0745e+00],\n",
       "          [ 1.1220e+00, -2.2964e+01, -5.9595e+00,  ..., -1.1613e+01,\n",
       "            6.5619e+00, -2.5560e+00],\n",
       "          [ 4.4377e+00, -2.4791e+00, -2.4301e+00,  ..., -6.6963e+00,\n",
       "            7.8470e+00,  4.8708e+00],\n",
       "          [ 1.7405e-03, -2.5593e+01, -1.0029e+01,  ...,  6.1088e+00,\n",
       "            1.9009e+01,  2.3103e+00],\n",
       "          [ 1.9933e+00, -1.5642e+01, -7.2224e-01,  ..., -7.1874e+00,\n",
       "            1.5647e+01,  9.0360e+00],\n",
       "          [ 4.2117e+00, -1.9546e+01,  7.6278e+00,  ...,  3.2308e+01,\n",
       "            1.4456e+01,  5.3858e+00]]], device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.40': tensor([[[  4.3971,  -7.1497,  -4.4404,  ...,  10.2163,   4.0496,  -7.4774],\n",
       "          [ -3.6071, -22.8042,  -3.1621,  ..., -11.7364,   1.1160, -13.7405],\n",
       "          [ -1.3940,   5.5629,  -0.0578,  ...,  -5.7087,   6.3175,   3.2471],\n",
       "          [ -5.5885, -14.8394,  -7.9080,  ...,   9.7216,  23.2999,   2.4425],\n",
       "          [ -7.2217,  -0.3589,  -7.5470,  ...,  -8.2844,  14.6356,   4.9846],\n",
       "          [  2.2727, -10.3106,  -1.5897,  ...,  34.9027,   7.4490,   7.9669]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.41': tensor([[[  3.8734,  -5.8669,   0.5494,  ...,   4.7550,   5.8057,  -7.8088],\n",
       "          [  9.8787, -16.1765,  -2.3796,  ...,  -8.0077,  -1.8888,  -6.3447],\n",
       "          [  0.7119,   7.9124,   0.3658,  ..., -15.4752,   7.2760,  16.9323],\n",
       "          [  4.0847,  -3.2459, -14.6653,  ...,   4.0203,  22.1313,  17.0654],\n",
       "          [ -5.6261,  -2.4134, -13.4821,  ..., -10.0184,  13.5462,  22.7838],\n",
       "          [  4.7206,  -9.9958, -15.5527,  ...,  42.6256,  12.4251,  21.3086]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.42': tensor([[[  5.8840, -16.6792,   8.1590,  ...,  36.5900,  42.0186, -21.0628],\n",
       "          [ 37.1106, -12.8622,  -3.6948,  ...,  -8.0815, -10.8341, -11.5358],\n",
       "          [  6.3929,  10.4203,  -7.0937,  ..., -14.7440,  15.4253,  30.1030],\n",
       "          [ 20.2643,   3.0620, -15.5732,  ...,  -0.7624,  18.7509,  16.5546],\n",
       "          [  2.1293,  13.1502, -13.6959,  ..., -11.2365,  22.5294,  43.2282],\n",
       "          [ -2.1608, -12.0932,  -7.2804,  ...,  53.9501,  30.3526,   9.5259]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.43': tensor([[[ 12.3024,  -1.6377,  16.9936,  ...,  37.8250,  67.9645, -24.4078],\n",
       "          [ 21.1123, -13.7914,   7.9449,  ..., -11.3274,  -7.8360,  -7.6677],\n",
       "          [ 13.2636,   2.3555,   0.4895,  ..., -18.2316,  25.6822,  38.9137],\n",
       "          [ -5.1686,   7.8020, -23.3218,  ...,   0.5627,  26.0762,  15.8210],\n",
       "          [ -0.1362,  15.0613, -10.2978,  ..., -17.8282,  26.0216,  46.0182],\n",
       "          [  8.5510,  16.0167,  -4.1151,  ...,  49.9339,  41.3937,  22.7735]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.44': tensor([[[  9.3461, -14.1678,  18.8951,  ...,  68.5526,  81.3092, -67.3674],\n",
       "          [  0.3778, -29.7530,   8.0679,  ...,  12.8665, -18.2275, -27.5926],\n",
       "          [ 24.0236,  -8.8449, -15.8668,  ...,   4.2719,   7.9946,  16.5535],\n",
       "          [-25.0357,  -8.7274, -36.3885,  ...,  18.0531,  31.3797,  -9.0198],\n",
       "          [ 19.7847,  17.0616, -19.4605,  ...,   2.1520,  14.3955,  32.7839],\n",
       "          [ 11.1032,  15.5032, -16.6160,  ...,  65.0580,  38.5645,   1.2484]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.45': tensor([[[  2.3282, -50.1046,  11.6122,  ...,  91.3157,  85.6376, -43.5684],\n",
       "          [ 16.2072, -81.9265, -20.1751,  ...,  20.9156,  -0.1622, -59.4073],\n",
       "          [ 46.3510, -42.6860, -29.0067,  ...,   9.2757,  33.1702,  29.0240],\n",
       "          [ -1.6267, -44.4921, -51.2881,  ...,  36.7950,  31.3385, -47.5390],\n",
       "          [ 50.6672,  -6.2290, -45.7407,  ...,  27.7943,  49.0676,  54.5645],\n",
       "          [ 28.5388, -17.5808, -39.9595,  ...,  77.8815,  49.0497,  19.0834]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.46': tensor([[[ 60.5082, -50.4436,  48.1667,  ..., 162.2819,  90.4246, -74.9654],\n",
       "          [ 76.4524, -78.2043,  37.5283,  ...,  55.0728, -28.4729, -50.4913],\n",
       "          [103.9179, -39.2728,  18.9438,  ...,  53.1701,  73.1354,  19.3023],\n",
       "          [ 89.3074, -39.4602,   6.2339,  ...,  84.7689,  21.7334, -43.5896],\n",
       "          [ 99.1652, -19.1012,   8.5616,  ...,  76.5912, 108.4017,  65.2262],\n",
       "          [ 61.3357, -19.1616, -10.2887,  ..., 145.4660,  68.2133, -18.6549]]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'transformer.blocks.47': tensor([[[ 140.4059,  -46.1480,   83.0700,  ...,  115.5777,  119.0854,\n",
       "           -112.1193],\n",
       "          [ 148.1072,  -74.6317,   14.7944,  ...,   58.2031,  -33.4255,\n",
       "            -10.0626],\n",
       "          [ 196.5655,  -57.0387,  -12.8319,  ...,   50.0533,   82.9065,\n",
       "             18.9139],\n",
       "          [ 155.8727,  -21.3833,  -13.7182,  ...,  116.4996,   54.5059,\n",
       "             11.2495],\n",
       "          [ 210.6618,  -36.5972,  -24.5372,  ...,   86.9121,  143.7358,\n",
       "             42.2693],\n",
       "          [ 105.1352,   20.2833,   -3.1216,  ...,  110.2784,  149.4312,\n",
       "            -67.6146]]], device='cuda:0', grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor.get_outputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b25a5-e2f7-4b95-abb5-3d863e66abf5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b86a6bf-00eb-4c8c-9b0c-72be443f5cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e34fe08e-4270-4279-9973-eaeb190f605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"timm/vgg16.tv_in1k\"\n",
    "inferencer = activation_extractor.Inferencer(model_name, device='cuda', half=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42197cb2-8548-417c-8b92-b9a6ce5c5027",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#intermediate activation extractor\n",
    "layers_to_hook = activation_extractor.get_layers_to_hook(inferencer.model,inferencer.model_type)\n",
    "extractor = activation_extractor.IntermediateExtractor(inferencer.model, layers_to_hook)\n",
    "extractor.register_hooks()\n",
    "\n",
    "#inference\n",
    "processed = inferencer.process(sequences) #tokenize\n",
    "outputs = inferencer.inference(processed)\n",
    "\n",
    "#extractor outputs\n",
    "#extractor.save_outputs('results/embeddings/test')\n",
    "extractor.clear_all_hooks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4548feef-b365-49de-b4fd-6f0700bb4acd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extractor.get_outputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb57c03-d901-40ff-b877-b0bf0a0baff7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "678b482e-d287-4d2b-bbe6-c52845990bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "text = [\"a photo of a cat\", \"a photo of a dog\"]\n",
    "\n",
    "input_data = {\"text\":text,\n",
    "             \"image\":image}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f33dc55e-9506-4e38-b108-6ba003cd11e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"openai/clip-vit-base-patch32\"\n",
    "inferencer = activation_extractor.Inferencer(model_name, device='cuda', half=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df6a2c63-bad0-495f-8951-00556b0582b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intermediate activation extractor\n",
    "layers_to_hook = activation_extractor.get_layers_to_hook(inferencer.model,inferencer.model_type)\n",
    "extractor = activation_extractor.IntermediateExtractor(inferencer.model, layers_to_hook)\n",
    "extractor.register_hooks()\n",
    "\n",
    "#inference\n",
    "processed = inferencer.process(sequences) #tokenize\n",
    "outputs = inferencer.inference(processed)\n",
    "\n",
    "#extractor outputs\n",
    "#extractor.save_outputs('results/embeddings/test')\n",
    "extractor.clear_all_hooks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1d5a68f-986f-48da-bddd-cbf2b6e6ba39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extractor.get_outputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1483d3-2e8c-40f5-8937-20330a2f4166",
   "metadata": {},
   "source": [
    "# Inference Over a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b6a8238-ab54-472e-a9fd-23d894663e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from activation_extractor.scripts.inference import main_inference, load_the_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b99e0f4-600c-4cbe-8c97-b21e873ab0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"Rostlab/ProstT5\"\n",
    "output_folder=\"test\"\n",
    "emb_format=\"mean\"\n",
    "save_method=\"numpy\"\n",
    "max_batches=1\n",
    "\n",
    "data_args = {\n",
    "        \"data_type\":\"protein\",\n",
    "        \"batch_size\":8,\n",
    "        \"data_source\":\"huggingface\",\n",
    "        \"dataset_name\":\"proteinea/remote_homology\",\n",
    "        \"dataset_partition\":\"train\",\n",
    "        \"target_col\":\"primary\",\n",
    "        # \"data_source\":\"local\",\n",
    "        # \"target_col\":\"protein_seq\",\n",
    "        # \"input_path\":\"/orfeo/LTS/LADE/LT_storage/bio_data/NCBI/NCBI_GP_from_geneid_Plt1000_Glt6000.csv\",\n",
    "        \"max_length\":1000,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a2d0d56-373d-4ea0-99ca-6efd4cbb29d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VEWTQQERSIIAGIFANLNYEDIGPKALARCLIVYPWTQRYFGAYGDLSTPDAIKGNAKIAAHGVKVLHGLDRAVKNMDNINEAYSELSVLHSDKLHVDPDNFRILGDCLTVVIAANLGDAFTVETQCAFQKFLAVVVFALGRKYH',\n",
       " 'PIVDTGSVAPLSAAEKTKIRSAWAPVYSTYETSGVDILVKFFTSTPAAQEFFPKFKGLTTADELKKSADVRWHAERIINAVDDAVASMDDTEKMSMKLRNLSGKHAKSFQVDPEYFKVLAAVIADTVAAGDAGFEKLMSMICILLRSAY',\n",
       " 'LSAAQKDNVKSSWAKASAAWGTAGPEFFMALFDAHDDVFAKFSGLFSGAAKGTVKNTPEMAAQAQSFKGLVSNWVDNLDNAGALEGQCKTFAANHKARGISAGQLEAAFKVLAGFMKSYGGDEGAWTAVAGALMGMIRPDM',\n",
       " 'GATQSFQSVGDLTPAEKDLIRSTWDQLMTHRTGFVADVFIRIFHNDPTAQRKFPQMAGLSPAELRTSRQMHAHAIRVSALMTTYIDEMDTEVLPELLATLTRTHDKNHVGKKNYDLFGKVLMEAIKAELGVGFTKQVHDAWAKTFAIVQGVLITKHAS',\n",
       " 'VKLSEDQEHYIKGVWKDVDHKQITAKALERVFVVYPWTTRLFSKLQGLFSANDIGVQQHADKVQRALGEAIDDLKKVEINFQNLSGKHQEIGVDTQNFKLLGQTFMVELALHYKKTFRPKEHAAAYKFFRLVAEALSSNYH',\n",
       " 'GLSAAQRQVVASTWKDIAGADNGAGVGKECLSKFISAHPEMAAVFGFSGASDPGVAELGAKVLAQIGVAVSHLGDEGKMVAEMKAVGVRHKGYGNKHIKAEYFEPLGASLLSAMEHRIGGKMNAAAKDAWAAAYGDISGALISGLQS',\n",
       " 'NAADRVMQSYGRCCASTGFFDDFYRHFLASSPQIRAKFATTDMTAQKHLLRAGIMNLVMYARGMSDSKLRALGASHSRAALDIRPELYDLWLDALLMAVAEHDRDCDAETRDAWRDVMGRGIAVIKSYYGS',\n",
       " 'ETAYFSDSNGQQKNRIQLTNKHADVKKQLKMVRLGDAELYVLEQLQPLIQENIVNIVDAFYKNLDHESSLMDIINDHSSVDRLKQTLKRHIQEMFAGVIDDEFIEKRNRIASIHLRIGLLPKWYMGAFQELLLSMIDIYEASITNQQELLKAIKATTKILNLEQQLVLE']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = load_the_data(**data_args)\n",
    "batch = next(iter(data_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e647a010-964a-4c7b-84d7-bc0c9ef15a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folder is: test/Rostlab/ProstT5/mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "✔️ Rostlab/ProstT5\n"
     ]
    }
   ],
   "source": [
    "main_inference(model_name, output_folder, emb_format, save_method, max_batches, data_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f3776-1571-4afe-81c1-42b9fc4817c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## For Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b5b943d-29da-478e-8e6c-62b9c7ca2db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"facebook/convnext-tiny-224\"\n",
    "output_folder=\"test\"\n",
    "emb_format=\"mean\"\n",
    "save_method=\"numpy\"\n",
    "max_batches=1\n",
    "\n",
    "data_args = {\n",
    "        \"data_type\":\"image\",\n",
    "        \"target_col\":\"img\",\n",
    "        \"batch_size\":1,\n",
    "        \"data_source\":\"huggingface\",\n",
    "        \"dataset_name\":\"uoft-cs/cifar100\",\n",
    "        \"dataset_partition\":\"train\",\n",
    "        # \"data_source\":\"local\",\n",
    "        # \"input_path\":\"test.csv\",\n",
    "        \"max_length\":999,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cf19605-8978-4d64-b79f-a31a2dd9cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_pil(batch):\n",
    "    \"\"\"\n",
    "    Convert PIL images to numpy arrays.\n",
    "    \"\"\"\n",
    "    batch = [np.array(img) for img in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11f42446-953d-4e33-8f31-ea8184c7c108",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [ np.array(dataset[\"train\"][\"img\"][i]) for i in range(10) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7169b68-643b-46c8-829d-1428e8a35e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "49c0cb2d-6f19-4937-9ee0-a54d76dfe23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR100\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "65508f08-305e-4d22-80d6-9a141ec40331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Define the transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))  # Normalize the images\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR100(\n",
    "    root='./data',  # Directory to store the dataset\n",
    "    train=True,  # Download the training dataset\n",
    "    download=True,  # Download if not already downloaded\n",
    "    transform=transform  # Apply transformations\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,  # Number of samples per batch\n",
    "    shuffle=True,  # Shuffle the dataset\n",
    "    num_workers=2,  # Number of subprocesses to use for data loadingt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18357c87-50c0-4f2e-90fb-80238e770017",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(train_dataset, batch_size=2, \n",
    "                             shuffle=False, collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "823a8310-3ef3-4731-b82c-9b9b49645ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "dataset = load_dataset(\"uoft-cs/cifar100\")\n",
    "data_loader = DataLoader(dataset[\"train\"], batch_size=2, \n",
    "                             shuffle=False, collate_fn=collate_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9084975e-1fed-4121-a84e-bee17a2de07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = load_the_data(**data_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e9b0dfb-2617-4495-ba42-04ac8d451238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[ 0.2153,  0.5819,  0.2593,  ...,  1.3588,  1.3002,  1.1829],\n",
       "           [ 0.1714,  0.4646,  0.2447,  ...,  1.2269,  1.0656,  1.1096],\n",
       "           [ 0.0101, -0.0339, -0.1072,  ...,  0.5965,  0.6552,  0.9630],\n",
       "           ...,\n",
       "           [-1.1480, -1.1334, -1.2360,  ..., -1.2507, -1.1041, -1.0894],\n",
       "           [-1.1774, -1.1627, -1.2653,  ..., -1.2067, -1.0747, -0.6496],\n",
       "           [-1.2213, -1.2213, -1.2946,  ..., -0.1951,  0.3473,  1.0510]],\n",
       " \n",
       "          [[-0.1240,  0.4417,  0.0901,  ...,  1.4661,  1.4966,  1.2979],\n",
       "           [-0.1393,  0.2735,  0.0442,  ...,  1.2979,  1.1297,  1.1603],\n",
       "           [-0.2157, -0.3074, -0.3380,  ...,  0.3958,  0.4111,  0.7781],\n",
       "           ...,\n",
       "           [-1.2706, -1.2553, -1.3624,  ..., -1.4235, -1.4082, -1.4541],\n",
       "           [-1.3165, -1.2859, -1.3776,  ..., -1.4694, -1.4388, -0.8731],\n",
       "           [-1.3471, -1.3471, -1.4235,  ..., -0.3686,  0.3041,  1.2214]],\n",
       " \n",
       "          [[-0.0199,  0.4914,  0.2073,  ...,  1.5708,  1.5992,  1.3436],\n",
       "           [-0.0483,  0.3493,  0.1647,  ...,  1.4004,  1.1874,  1.1874],\n",
       "           [-0.0768, -0.1762, -0.2472,  ...,  0.4914,  0.4772,  0.8181],\n",
       "           ...,\n",
       "           [-0.8579, -0.8437, -1.0142,  ..., -1.0994, -1.0994, -1.1136],\n",
       "           [-0.9006, -0.8864, -1.0426,  ..., -1.1136, -1.1136, -0.6307],\n",
       "           [-0.9716, -0.9716, -1.0426,  ..., -0.1336,  0.4914,  1.2868]]],\n",
       " \n",
       " \n",
       "         [[[ 0.2300,  0.2447,  0.3033,  ...,  0.4499,  0.4353,  0.4792],\n",
       "           [ 0.3766,  0.3913,  0.4206,  ...,  0.5672,  0.5232,  0.5525],\n",
       "           [ 0.5232,  0.5232,  0.5525,  ...,  0.6698,  0.5819,  0.5965],\n",
       "           ...,\n",
       "           [ 1.0510,  1.0950,  1.1536,  ...,  0.9337,  1.4175,  1.5054],\n",
       "           [ 1.1536,  1.0950,  1.1096,  ...,  1.3735,  1.4468,  1.4175],\n",
       "           [ 0.9777,  1.0510,  1.2416,  ...,  1.3588,  1.3442,  1.3442]],\n",
       " \n",
       "          [[ 1.0686,  1.0838,  1.1450,  ...,  1.2826,  1.2673,  1.2214],\n",
       "           [ 1.1756,  1.1756,  1.2214,  ...,  1.3285,  1.3132,  1.2673],\n",
       "           [ 1.2520,  1.2367,  1.2826,  ...,  1.3438,  1.2979,  1.2826],\n",
       "           ...,\n",
       "           [ 1.2520,  1.2826,  1.3285,  ...,  0.9921,  1.4966,  1.5884],\n",
       "           [ 1.2214,  1.1909,  1.2062,  ...,  1.4814,  1.5578,  1.4966],\n",
       "           [ 1.0991,  1.1909,  1.3896,  ...,  1.5272,  1.4814,  1.4355]],\n",
       " \n",
       "          [[ 1.5282,  1.5424,  1.5850,  ...,  1.5850,  1.6419,  1.6277],\n",
       "           [ 1.6561,  1.6419,  1.6845,  ...,  1.6703,  1.7129,  1.6987],\n",
       "           [ 1.6845,  1.6703,  1.7129,  ...,  1.6845,  1.6987,  1.6987],\n",
       "           ...,\n",
       "           [ 1.1874,  1.2158,  1.2584,  ...,  0.8891,  1.3720,  1.4856],\n",
       "           [ 1.1874,  1.1731,  1.2016,  ...,  1.3578,  1.4430,  1.4288],\n",
       "           [ 1.0453,  1.1305,  1.3152,  ...,  1.4288,  1.3862,  1.3720]]],\n",
       " \n",
       " \n",
       "         [[[-0.4737, -0.5030, -0.5030,  ...,  0.1274,  1.1976,  0.8751],\n",
       "           [-0.5030, -0.5177, -0.5177,  ...,  0.2007,  1.0656,  1.4468],\n",
       "           [-0.5030, -0.5177, -0.5177,  ..., -0.3124,  0.8897,  1.4028],\n",
       "           ...,\n",
       "           [ 0.4206,  0.3473,  0.2740,  ...,  0.2007,  0.2886,  0.3913],\n",
       "           [ 0.2300,  0.1420,  0.0687,  ...,  0.2007,  0.4792,  0.7138],\n",
       "           [ 0.6991,  0.6405,  0.6258,  ...,  0.6845,  0.7285,  0.8164]],\n",
       " \n",
       "          [[-1.1942, -1.1942, -1.1942,  ..., -0.8120,  0.4111,  0.4723],\n",
       "           [-1.1942, -1.2095, -1.2095,  ..., -0.7661,  0.1512,  0.9462],\n",
       "           [-1.1942, -1.2095, -1.2095,  ..., -1.1177, -0.1393,  0.6099],\n",
       "           ...,\n",
       "           [-0.0628, -0.1393, -0.1698,  ..., -0.1851, -0.1240, -0.0781],\n",
       "           [-0.2310, -0.2769, -0.2769,  ..., -0.2463, -0.1087,  0.0289],\n",
       "           [ 0.2277,  0.1818,  0.1665,  ...,  0.2124,  0.2430,  0.2888]],\n",
       " \n",
       "          [[-1.0142, -1.0142, -1.0142,  ..., -0.9006, -0.1762,  0.0937],\n",
       "           [-1.0142, -1.0284, -1.0284,  ..., -0.9574, -0.4318,  0.3209],\n",
       "           [-1.0284, -1.0284, -1.0284,  ..., -1.0426, -0.6733, -0.0483],\n",
       "           ...,\n",
       "           [-1.4403, -1.4403, -1.4545,  ..., -1.4687, -1.3977, -1.3835],\n",
       "           [-1.4829, -1.5113, -1.5397,  ..., -1.3977, -1.3125, -1.3267],\n",
       "           [-1.5539, -1.5539, -1.5681,  ..., -1.5113, -1.5113, -1.4971]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.3417, -0.2391, -0.1218,  ...,  0.3913,  0.3766,  0.3326],\n",
       "           [-0.3271, -0.2831, -0.2098,  ...,  0.3033,  0.3180,  0.3033],\n",
       "           [-0.2831, -0.1805, -0.1072,  ...,  0.1714,  0.2153,  0.1860],\n",
       "           ...,\n",
       "           [-1.6172, -1.6465, -1.6318,  ..., -1.3826, -1.3826, -1.3973],\n",
       "           [-1.6611, -1.6465, -1.6172,  ..., -1.4119, -1.4119, -1.4119],\n",
       "           [-1.6905, -1.6465, -1.6025,  ..., -1.4266, -1.4412, -1.4412]],\n",
       " \n",
       "          [[ 0.5487,  0.6252,  0.7169,  ...,  1.0380,  1.0227,  0.9768],\n",
       "           [ 0.5793,  0.5793,  0.6252,  ...,  0.9462,  0.9615,  0.9462],\n",
       "           [ 0.6252,  0.6863,  0.7322,  ...,  0.8239,  0.8698,  0.8392],\n",
       "           ...,\n",
       "           [-1.2859, -1.3012, -1.2706,  ..., -0.9343, -0.8884, -0.8884],\n",
       "           [-1.3471, -1.3471, -1.3012,  ..., -0.9954, -0.9496, -0.9801],\n",
       "           [-1.3776, -1.3471, -1.3012,  ..., -1.0413, -1.0260, -1.0719]],\n",
       " \n",
       "          [[ 1.1874,  1.2158,  1.3010,  ...,  1.4856,  1.4714,  1.4430],\n",
       "           [ 1.2016,  1.1874,  1.2300,  ...,  1.4146,  1.4288,  1.4146],\n",
       "           [ 1.2442,  1.2868,  1.3152,  ...,  1.3010,  1.3436,  1.3152],\n",
       "           ...,\n",
       "           [-0.5313, -0.5739, -0.5597,  ..., -0.2898, -0.2472, -0.2188],\n",
       "           [-0.6023, -0.6165, -0.5881,  ..., -0.3324, -0.3040, -0.3040],\n",
       "           [-0.6449, -0.6165, -0.5739,  ..., -0.3608, -0.3466, -0.3750]]],\n",
       " \n",
       " \n",
       "         [[[ 0.4059,  0.3619,  0.3033,  ...,  0.2886,  0.2886,  0.2740],\n",
       "           [ 0.4499,  0.5086,  0.4939,  ...,  0.2886,  0.2886,  0.2886],\n",
       "           [ 0.3473,  0.4206,  0.4206,  ..., -0.0046,  0.0101,  0.0101],\n",
       "           ...,\n",
       "           [-0.9135, -0.9428, -0.9428,  ...,  0.5379,  0.0101, -0.4004],\n",
       "           [-0.8695, -0.8988, -0.8988,  ...,  0.1420,  0.1420, -0.4004],\n",
       "           [-0.7962, -0.8255, -0.8402,  ...,  0.1127,  0.2300, -0.2538]],\n",
       " \n",
       "          [[ 0.4111,  0.3194,  0.1818,  ...,  0.3347,  0.3347,  0.3194],\n",
       "           [ 0.5793,  0.5946,  0.5334,  ...,  0.2735,  0.2735,  0.2735],\n",
       "           [ 0.5334,  0.5793,  0.5640,  ..., -0.0322, -0.0169, -0.0169],\n",
       "           ...,\n",
       "           [-0.2769, -0.2769, -0.2616,  ...,  0.8392,  0.7169,  0.3958],\n",
       "           [-0.2616, -0.2769, -0.2463,  ...,  0.3194,  0.7628,  0.3958],\n",
       "           [-0.2463, -0.2463, -0.2463,  ...,  0.3194,  0.6710,  0.5029]],\n",
       " \n",
       "          [[ 0.2215,  0.1221, -0.0483,  ...,  0.0653,  0.0511,  0.0369],\n",
       "           [ 0.4630,  0.4630,  0.3636,  ..., -0.3466, -0.3324, -0.3182],\n",
       "           [ 0.3636,  0.4488,  0.5056,  ..., -1.2414, -1.1704, -1.1846],\n",
       "           ...,\n",
       "           [-0.5171, -0.4602, -0.4176,  ...,  0.2215,  0.3920, -0.3040],\n",
       "           [-0.4745, -0.4176, -0.3608,  ..., -0.6449,  0.5766, -0.2046],\n",
       "           [-0.4460, -0.3892, -0.3466,  ..., -1.2698,  0.3920,  0.2073]]],\n",
       " \n",
       " \n",
       "         [[[-0.5763, -0.6643, -0.6643,  ..., -1.5878, -1.4412, -1.7344],\n",
       "           [-0.5323, -0.5910, -0.6496,  ..., -1.4412, -1.1627, -1.6465],\n",
       "           [-0.5323, -0.5763, -0.5763,  ..., -1.0014, -0.3124, -0.4590],\n",
       "           ...,\n",
       "           [-0.1218, -0.0632, -0.1512,  ...,  0.7285,  0.7578,  0.6845],\n",
       "           [-0.1365, -0.0046,  0.1127,  ...,  0.5672,  0.5819,  0.7431],\n",
       "           [ 0.1274,  0.1274,  0.4499,  ...,  0.2740,  0.3619,  0.6552]],\n",
       " \n",
       "          [[-1.2859, -1.3624, -1.3624,  ..., -1.7599, -1.6070, -1.7752],\n",
       "           [-1.2706, -1.3165, -1.3776,  ..., -1.6528, -1.2859, -1.6070],\n",
       "           [-1.3165, -1.3624, -1.3624,  ..., -1.3318, -0.5673, -0.5062],\n",
       "           ...,\n",
       "           [-1.1177, -1.0107, -1.1942,  ..., -0.6591, -0.6132, -0.6744],\n",
       "           [-1.0260, -0.8120, -0.8273,  ..., -0.6897, -0.6897, -0.6285],\n",
       "           [-0.6132, -0.5215, -0.3686,  ..., -0.8425, -0.7661, -0.6744]],\n",
       " \n",
       "          [[-1.2272, -1.2983, -1.2983,  ..., -1.4829, -1.3551, -1.5255],\n",
       "           [-1.1988, -1.2414, -1.2983,  ..., -1.3977, -1.0710, -1.3835],\n",
       "           [-1.2272, -1.2556, -1.2698,  ..., -1.0568, -0.3182, -0.2898],\n",
       "           ...,\n",
       "           [-1.1704, -1.0852, -1.2130,  ..., -0.6165, -0.5739, -0.6307],\n",
       "           [-1.0284, -0.8295, -0.8579,  ..., -0.6165, -0.6307, -0.5881],\n",
       "           [-0.5739, -0.4745, -0.3892,  ..., -0.7727, -0.7443, -0.6449]]]]),\n",
       " tensor([19, 71, 98, 46, 46, 57, 18, 73, 95, 63, 60, 56,  7, 63, 20, 34,  2, 19,\n",
       "         36, 91, 30, 15, 77, 70, 44, 30, 27, 62, 23, 86, 26, 73, 59, 22,  4, 33,\n",
       "         18, 64, 38, 53, 80, 97, 76, 69, 14, 59, 75,  8, 73, 43, 22, 91, 48, 53,\n",
       "          3, 34, 83, 40, 65, 96, 81, 30,  1,  8])]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fbb3c80-f9cf-4c2c-a8a7-de23aa879617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folder is: test/facebook/convnext-tiny-224/mean\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid image type. Expected either PIL.Image.Image, numpy.ndarray, torch.Tensor, tf.Tensor or jax.ndarray, but got <class 'NoneType'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/orfeo/cephfs/scratch/area/evillegas/glm/activation-extractor/src/activation_extractor/scripts/inference.py:207\u001b[0m, in \u001b[0;36mmain_inference\u001b[0;34m(model_name, output_folder, emb_format, save_method, max_batches, data_args)\u001b[0m\n\u001b[1;32m    202\u001b[0m start_total_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):   \n\u001b[1;32m    205\u001b[0m     \u001b[38;5;66;03m### Inference Part ###\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;66;03m#process\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[43minferencer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m#inference\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/orfeo/cephfs/scratch/area/evillegas/glm/activation-extractor/src/activation_extractor/inferencers/inferencerBase.py:72\u001b[0m, in \u001b[0;36mInferencerBase.process\u001b[0;34m(self, input_data, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    Process input data (tokenize or image processing).\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    The tokenizer works with batches of sequences (list of strings).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :return: the processed inputs\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m     processed_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m processed_input\n",
      "File \u001b[0;32m/orfeo/cephfs/scratch/area/evillegas/glm/activation-extractor/src/activation_extractor/model_functions/process_funs.py:22\u001b[0m, in \u001b[0;36mdefine_process_function.<locals>.process_fun\u001b[0;34m(image, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_fun\u001b[39m(image, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 22\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m processed\n",
      "File \u001b[0;32m/orfeo/cephfs/scratch/area/evillegas/glm/dgxtorch/lib/python3.10/site-packages/transformers/image_processing_utils.py:551\u001b[0m, in \u001b[0;36mBaseImageProcessor.__call__\u001b[0;34m(self, images, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, images, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchFeature:\n\u001b[1;32m    550\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Preprocess an image or a batch of images.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/orfeo/cephfs/scratch/area/evillegas/glm/dgxtorch/lib/python3.10/site-packages/transformers/models/convnext/image_processing_convnext.py:281\u001b[0m, in \u001b[0;36mConvNextImageProcessor.preprocess\u001b[0;34m(self, images, do_resize, size, crop_pct, resample, do_rescale, rescale_factor, do_normalize, image_mean, image_std, return_tensors, data_format, input_data_format, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m size \u001b[38;5;241m=\u001b[39m get_size_dict(size, default_to_square\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    279\u001b[0m validate_kwargs(captured_kwargs\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mkeys(), valid_processor_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valid_processor_keys)\n\u001b[0;32m--> 281\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mmake_list_of_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid_images(images):\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid image type. Must be of type PIL.Image.Image, numpy.ndarray, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Tensor, tf.Tensor or jax.ndarray.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m     )\n",
      "File \u001b[0;32m/orfeo/cephfs/scratch/area/evillegas/glm/dgxtorch/lib/python3.10/site-packages/transformers/image_utils.py:165\u001b[0m, in \u001b[0;36mmake_list_of_images\u001b[0;34m(images, expected_ndims)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    161\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid image shape. Expected either \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_ndims\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_ndims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, but got\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimages\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         )\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m images\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid image type. Expected either PIL.Image.Image, numpy.ndarray, torch.Tensor, tf.Tensor or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjax.ndarray, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(images)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid image type. Expected either PIL.Image.Image, numpy.ndarray, torch.Tensor, tf.Tensor or jax.ndarray, but got <class 'NoneType'>."
     ]
    }
   ],
   "source": [
    "main_inference(model_name, output_folder, emb_format, save_method, max_batches, data_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4aed7ba3-cc35-4cdb-b9f3-c87d98e99c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ds[\"train\"][\"img\"][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c0ff80e-201d-47d3-bbd9-2c52cc0fe127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbdc93caa9234e639d59e63d6b6a854e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/18.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ed6b9dfe2b4690bd32fe473af90944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/591753 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"ChristophSchuhmann/MS_COCO_2017_URL_TEXT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93418bf5-72e3-4819-9979-bc1c1cf1cb2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://images.cocodataset.org/train2017/000000391895.jpg'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train']['URL'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a9c5a3-8699-4600-921c-40b1c8a880e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
